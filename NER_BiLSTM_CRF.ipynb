{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NER BiLSTM CRF final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTemWQxwFGSi",
        "outputId": "db77c019-3863-446d-9992-8860ae23e355"
      },
      "source": [
        "import sys\n",
        "{sys.executable}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/usr/bin/python3'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qp7L4ubxUjc3",
        "outputId": "dcbee73e-8e39-453f-99fe-0de7f51bd678"
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.9.0+cu102'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84_dmCOSVL0d",
        "outputId": "1c1db30f-e4ab-4f4f-861e-465c1d34ad32"
      },
      "source": [
        "!pip install jdc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jdc\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/cb/9afea749985eef20f3160e8826a531c7502e40c35a038dfe49b67726e9a0/jdc-0.0.9-py2.py3-none-any.whl\n",
            "Installing collected packages: jdc\n",
            "Successfully installed jdc-0.0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P3WMq5aUmZR",
        "outputId": "64ae7087-bbb1-4776-d3d8-68ffd3da808f"
      },
      "source": [
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import jdc\n",
        "import json\n",
        "from collections import defaultdict, OrderedDict\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7db3997a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBFADJb1UrSy",
        "outputId": "8f8fb600-07f9-4605-ba1e-18f63ffdbad1"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G43P4qxbVWBD"
      },
      "source": [
        "def argmax(vec):\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr6GFLsMYkWA",
        "outputId": "4ae3209c-30b7-49b2-fe01-28756c8e4d2e"
      },
      "source": [
        "with open('allData.json', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "print(json.loads(lines[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'id': 2503, 'data': '@slycbiskut way much rain here gettin colder nothing like guys get', 'label': [[0, 11, 'B-PERSON'], [26, 30, 'B-LOC'], [38, 44, 'B-EVENT']]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdEJ1s89Cvbh",
        "outputId": "b51fbc19-5319-4733-f97e-d31d838307c2"
      },
      "source": [
        "# ix_to_label = {8: 'O', 7: 'I-LOC', 6: 'B-LOC' , 5: 'I-PER', 4: 'B-PER', 3: 'I-EVENT', 2: 'B-EVENT'}\n",
        "\n",
        "data = []\n",
        "vocab = set()\n",
        "\n",
        "for line in lines:\n",
        "  # print(line)\n",
        "  words = []\n",
        "  labels = []\n",
        "  injson = json.loads(line)\n",
        "  # print(injson)\n",
        "  annots = injson['label']\n",
        "  text = injson['data']\n",
        "  split_text = text.split(\" \")\n",
        "  orddict = OrderedDict({})\n",
        "  for ann in annots:\n",
        "    orddict[text[ann[0]:(ann[1]+1)].rstrip()] = ann[2]\n",
        "  # print(orddict)\n",
        "\n",
        "  for word in split_text:\n",
        "    words.append(word)\n",
        "    vocab.add(word)\n",
        "    labels.append(orddict.get(word, 'O'))\n",
        "  data.append((words, labels))\n",
        "  \n",
        "print(data[1])       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['@slycbiskut', 'way', 'much', 'rain', 'here', 'gettin', 'colder', 'nothing', 'like', 'guys', 'get'], ['B-PERSON', 'O', 'O', 'O', 'B-LOC', 'O', 'B-EVENT', 'O', 'O', 'O', 'O'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKH6JHnC8_rQ"
      },
      "source": [
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ6t2lac8_t_"
      },
      "source": [
        "training_data = []\n",
        "lines = []\n",
        "with open('tagged_lines.txt', 'r') as f:\n",
        "  all_lines = csv.reader(f, delimiter = \"\\t\")\n",
        "  lines = list(all_lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwd6uwhg8_xE",
        "outputId": "10ebbdc3-ea37-424a-b26e-4b5a36d48469"
      },
      "source": [
        "len(lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31831"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g4c2xA48_0M"
      },
      "source": [
        "lines[29107] = ['Tite', 'O']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cOvqIif8_22",
        "outputId": "34b919cd-47b6-48c0-d431-8aaf3707555b"
      },
      "source": [
        "print((lines[29107]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Tite', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLPSOagd8_5w"
      },
      "source": [
        "sentence = []\n",
        "tags = []\n",
        "for i in range(len(lines)):\n",
        "  if lines[i] == []:\n",
        "    training_data.append((sentence, tags))\n",
        "    sentence = []\n",
        "    tags = []\n",
        "    continue\n",
        "  sentence.append(lines[i][0])\n",
        "  tags.append(lines[i][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZuO_OMy8_8r",
        "outputId": "86cdc3dc-9787-4c9a-f047-6314a759f22e"
      },
      "source": [
        "print(len(training_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGCVCSfk9diD",
        "outputId": "09dc1655-195d-4e31-819c-cc86477ab250"
      },
      "source": [
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5390\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXN50Fbt9dlK"
      },
      "source": [
        "training_data = training_data + data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1W8WhIf9eEq",
        "outputId": "1c8f6aa9-db16-49de-e68c-413c3ebf043d"
      },
      "source": [
        "print(training_data[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O', 'est', 'le', 'rapport', 'avec', 'les', 'philosophes', 'ici', 'On', 'traite', 'un', 'sujet', 'serieu', 'cyber', 'harclement', 'mais', 'malheureusement', 'de', 'nos', 'jours', 'il', 'faut', 'attendre', 'que', 'quelquun', 'se', 'suicide', 'pour', 'rendre', 'compte', 'du', 'rel', 'problme', 'cest']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nOfKVko_yzy"
      },
      "source": [
        "vocab = set()\n",
        "\n",
        "for i in range(len(training_data)):\n",
        "  for word in training_data[i][0]:\n",
        "    vocab.add(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBV7--qRcW0s"
      },
      "source": [
        "num_train = math.floor(len(data) * 0.7) \n",
        "training_data, test_data = data[:num_train], data[num_train:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmmV8fZkcW3h"
      },
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 16 # 8\n",
        "HIDDEN_DIM = 16  # 16\n",
        "MINIBATCH_SIZE = 2\n",
        "LEARNING_WEIGHT = 0.05\n",
        "WEIGHT_DECAY = 1e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfYm-O0FcW5y"
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        self.hidden = self.init_hidden()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fikXN-VLcW8c"
      },
      "source": [
        "%%add_to BiLSTM_CRF\n",
        "\n",
        "def init_hidden(self):\n",
        "    return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "            torch.randn(2, 1, self.hidden_dim // 2).to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt8uDkvQJ1Xh"
      },
      "source": [
        "%%add_to BiLSTM_CRF\n",
        "\n",
        "def _forward_alg(self, feats):\n",
        "    \n",
        "    init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "    init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "    forward_var = init_alphas\n",
        "    for feat in feats:\n",
        "        alphas_t = []  \n",
        "        for next_tag in range(self.tagset_size):\n",
        "            emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
        "            trans_score = self.transitions[next_tag].view(1, -1)\n",
        "            next_tag_var = forward_var + trans_score + emit_score\n",
        "            alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "        forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "    terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "    alpha = log_sum_exp(terminal_var)\n",
        "    return alpha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwAfOxiUJ1dp"
      },
      "source": [
        "%%add_to BiLSTM_CRF\n",
        "\n",
        "def _get_lstm_features(self, sentence):\n",
        "    self.hidden = self.init_hidden()\n",
        "    embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "    lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "    lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "    lstm_feats = self.hidden2tag(lstm_out)\n",
        "    return lstm_feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VBWGUQgJ1i1"
      },
      "source": [
        "%%add_to BiLSTM_CRF\n",
        "\n",
        "def _score_sentence(self, feats, tags):\n",
        "    score = torch.zeros(1).to(device)\n",
        "    tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "    for i, feat in enumerate(feats):\n",
        "        score = score + self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "    score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8ef2TdtJ1sx"
      },
      "source": [
        "%%add_to BiLSTM_CRF\n",
        "\n",
        "def _viterbi_decode(self, feats):\n",
        "    backpointers = []\n",
        "    init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "    init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "    forward_var = init_vvars\n",
        "    for feat in feats:\n",
        "        bptrs_t = []  \n",
        "        viterbivars_t = []  \n",
        "\n",
        "        for next_tag in range(self.tagset_size):\n",
        "            next_tag_var = forward_var + self.transitions[next_tag]\n",
        "            best_tag_id = argmax(next_tag_var)\n",
        "            bptrs_t.append(best_tag_id)\n",
        "            viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "        forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1).to(device)\n",
        "        backpointers.append(bptrs_t)\n",
        "\n",
        "    terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "    best_tag_id = argmax(terminal_var)\n",
        "    path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "    best_path = [best_tag_id]\n",
        "    for bptrs_t in reversed(backpointers):\n",
        "        best_tag_id = bptrs_t[best_tag_id]\n",
        "        best_path.append(best_tag_id)\n",
        "    start = best_path.pop()\n",
        "    assert start == self.tag_to_ix[START_TAG] \n",
        "    best_path.reverse()\n",
        "    return path_score, best_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVteRGZrKGey"
      },
      "source": [
        "%%add_to BiLSTM_CRF\n",
        "\n",
        "def neg_log_likelihood(self, sentence, tags):\n",
        "    feats = self._get_lstm_features(sentence)\n",
        "    forward_score = self._forward_alg(feats)\n",
        "    gold_score = self._score_sentence(feats, tags)\n",
        "    return forward_score - gold_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abswgmw9KGhc"
      },
      "source": [
        "%%add_to BiLSTM_CRF\n",
        "\n",
        "def forward(self, sentence):\n",
        "    lstm_feats = self._get_lstm_features(sentence)\n",
        "    score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "    return score, tag_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SltYEOi1KGj8"
      },
      "source": [
        "def remove_punct(text):\n",
        "    punct = list(\".,()-\")\n",
        "    for p in punct:\n",
        "        text = text.replace(p, '')\n",
        "    return text\n",
        "    \n",
        "text = remove_punct(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOL7hlrSKGmX"
      },
      "source": [
        "word_to_ix = {k: v for (k, v) in zip(vocab, range(len(vocab)))}\n",
        "tag_to_ix = {'B-EVENT': 0, 'I-EVENT': 1, 'B-PERSON':2, 'I-PERSON':3, 'B-LOC':4, 'I-LOC':5, 'O':6, START_TAG: 7, STOP_TAG:8}\n",
        "ix_to_tag = {6: 'O', 5: 'I-LOC', 4: 'B-LOC' , 3: 'I-PERSON', 2: 'B-PERSON', 1: 'I-EVENT', 0: 'B-EVENT'}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osC5q601KGpI"
      },
      "source": [
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "model = model.to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_WEIGHT, weight_decay=WEIGHT_DECAY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-I2kV5IKGr2",
        "outputId": "67d726c4-aaf1-4b81-98e1-8c472b231f01"
      },
      "source": [
        "with torch.no_grad():\n",
        "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    precheck_sent = precheck_sent.to(device)\n",
        "    pred =  model(precheck_sent)[1]\n",
        "    print('Prediction:   ', [ix_to_tag[idx] for idx in pred])\n",
        "    print('Ground truth: ', training_data[0][1])\n",
        "    print(training_data[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction:    ['I-PERSON', 'O', 'I-LOC', 'I-EVENT', 'B-PERSON', 'I-LOC', 'I-EVENT', 'B-PERSON', 'I-EVENT', 'B-PERSON', 'I-LOC', 'I-EVENT', 'B-PERSON', 'I-LOC', 'I-EVENT', 'B-PERSON', 'I-LOC', 'I-EVENT', 'B-PERSON']\n",
            "Ground truth:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EVENT']\n",
            "['wwwwe', 'mmmmuch', 'timmmme', 'little', 'wwwwith', 'thats', 'wwwwhat', 'commmmes', 'wwwwith', 'mmmmidcaste', 'anything', 'commmmplain', 'lot', 'people', 'things', 'wwwworse', 'Oh', 'boy', 'depressed']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2OmQB2LKdf2"
      },
      "source": [
        "%%time\n",
        "\n",
        "losses = []\n",
        "for epoch in range(10):  \n",
        "    for sentence, tags in training_data:\n",
        "        model.zero_grad()\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
        "        sentence_in, targets = sentence_in.to(device), targets.to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(\"Epoch: {} Loss: {}\".format(epoch+1, np.mean(losses)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3tfbZ8wKdiQ"
      },
      "source": [
        "torch.save(model.state_dict(), 'model_70.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmRcMb6JEKuX",
        "outputId": "3a57c9a4-9c62-4915-ab4d-9cf747d0bdf0"
      },
      "source": [
        "model.eval() \n",
        "\n",
        "test_datum = training_data[0][0]\n",
        "test_text = training_data[0][1]\n",
        "\n",
        "with torch.no_grad():\n",
        "    precheck_sent = prepare_sequence(test_datum, word_to_ix)\n",
        "    precheck_sent = precheck_sent.to(device)\n",
        "    pred =  model(precheck_sent)[1]\n",
        "    print('Prediction:   ', [ix_to_tag[idx] for idx in pred])\n",
        "    print('Ground truth: ', test_text)\n",
        "    print('Text: ', test_datum)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction:    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EVENT']\n",
            "Ground truth:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EVENT']\n",
            "Text:  ['wwwwe', 'mmmmuch', 'timmmme', 'little', 'wwwwith', 'thats', 'wwwwhat', 'commmmes', 'wwwwith', 'mmmmidcaste', 'anything', 'commmmplain', 'lot', 'people', 'things', 'wwwworse', 'Oh', 'boy', 'depressed']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYUeZQeDEh78",
        "outputId": "48409bf5-82d5-47f1-9199-7f59e33ea9e6"
      },
      "source": [
        "model.eval() \n",
        "test_datum = test_data[198][0]\n",
        "test_text = test_data[198][1]\n",
        "\n",
        "with torch.no_grad():\n",
        "    precheck_sent = prepare_sequence(test_datum, word_to_ix)\n",
        "    precheck_sent = precheck_sent.to(device)\n",
        "    pred =  model(precheck_sent)[1]\n",
        "    print('Prediction:   ', [ix_to_tag[idx] for idx in pred])\n",
        "    print('Ground truth: ', test_text)\n",
        "    print('Text: ', test_datum)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction:    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Ground truth:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Text:  ['13', 'Reasons', 'trust', 'claim', '13', 'Reasons', 'Why', 'increased', 'youth', 'suicide', 'rates', 'Statistical', 'Modeling', 'Causal']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5K20HfoEiBU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZyHezUoKtU9"
      },
      "source": [
        "model.eval() \n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "  for i in range(len(test_data)):\n",
        "    y_true.append(test_data[i][1])\n",
        "    test_datum = test_data[i][0]\n",
        "    precheck_sent = prepare_sequence(test_datum, word_to_ix)\n",
        "    precheck_sent = precheck_sent.to(device)\n",
        "    pred =  model(precheck_sent)[1]\n",
        "    pred_tags = [ix_to_tag[idx] for idx in pred]\n",
        "    y_pred.append(pred_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p93Wq01UZQLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e501bc-5df5-40f3-adde-739972502bf9"
      },
      "source": [
        "pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTtQiz7tKtZz"
      },
      "source": [
        "from seqeval.metrics import accuracy_score\n",
        "from seqeval.metrics import classification_report\n",
        "from seqeval.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPIJrL__ZdLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c528be34-98fc-43d5-d443-c8f9d55af19c"
      },
      "source": [
        "accuracy_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9834037063101102"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CDTg2W62740",
        "outputId": "2c0af8aa-6c4a-4f55-d79d-e107937a57a9"
      },
      "source": [
        "f1_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6854724964739068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    }
  ]
}